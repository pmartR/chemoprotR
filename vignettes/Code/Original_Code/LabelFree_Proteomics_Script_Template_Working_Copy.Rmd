---
title: "3A Practice Data Analysis"
author: "Author: Gerard Lomas | Ran by: Gerard Lomas"
date: "Date Ran: 7/28/2022"
output: html_document
runtime: shiny
  
---
## Workflow Overview
  **Steps in Bold will require user input**

  I.  Set Working Environment 
        1. Load R Packages
        2. Create Functions
  II. **Load Initial Data Files**
        1. Mage Processor SicStats Results
        2. Protein Collection List 
  III. Clean Data
        1. **Enter FDR Filter ( MSGFSpecProb or QValue)**
        2. Clean Protein Syntax
        3. Spread Job and Peak Area Data Column-wise
  IV. Sum Redundant Peptides
  V.  Box Plots and Central Tendency Normalization 
        1. Pre-Normalization Box Plot 
        2. Central Tendency Normalization
        3. Normalized Box Plot 
        4. Anti log of Reporter Ions 
  VI. Protein Rollup 
  VII. Remove Reverse Hits and Contaminants 
  VIII. Add Protein Collection List
  IX. Statistical Analysis for each Comparision (ABP vs. NP, ABP vs. Comp)
        1. Create dataframe with only Test groups 
        2. Count Valid Values 
        3. Apply Presence/Absence Filter **(Save Resulting dataset)**
        4. Apply t-Test Valid Values Filter 
        5. Run t-test function 
        6. Run log2 Fold-Change function **(Save Resulting datast)**
  X. Create and Save Documentation and Datasets 
  
  

# **I. Set Working Environment**
```{r}
setwd("~/Desktop/")
```

## 1. Load R Packages 
```{r, message=FALSE}
library(tidyverse)
library(tidyr)
library(stringr)
library(ggplot2)
library(ggvis)
library(rmarkdown)
library(readxl)
library(dplyr)
library(reshape2)
library(matrixTests)
library(gtools)
library(knitr)
library(kableExtra)
library(shiny)
library(DT)

```

## 2. Create Functions
```{r}
MeanCenter.Sub <- function(Data, Mean=TRUE, centerZero=TRUE)
  {
  ndata <- Data
  
  # Compute the mean or median of each column in matrix Data, storing in vector Center
  if (Mean)
    Center <- apply(Data,2,mean,na.rm=TRUE)
  else
    Center <- apply(Data,2,median,na.rm=TRUE)
  
  # Transform vector Center into a matrix
  centerM <- matrix(Center,nrow=dim(Data)[1],ncol=dim(Data)[2], byrow=TRUE)
  
  if (centerZero)
  {
    # For data in each column, subtract the
    # column mean or median from the values, 
    # centering at zero
    ndata <- Data - centerM
  }
  else
  {
    # For data in each column, subtract the
    # column mean or median from the values, 
    # centering at the maximum mean or median
    newAverage <- max(Center,na.rm=TRUE)
    ndata <- Data - centerM + newAverage
  }
  return(ndata)
}
```


# II. Load Initial Data Files


### 1. Mage_Processor Results
```{r, message=FALSE, warning=FALSE}
Mage <- read_excel(paste0(here::here(),"/Data/LabelFree_Practice_Dataset.xlsx"), sheet = "Mage")

#Mage <- read_excel("3A_Practice_DataFiles.xlsx", sheet = "Mage")
```

```{r}
# DO NOT RUN THESE - IT WILL CAUSE COMPUTER TO GET MAD
# DT::datatable(
#    Mage,
#    clas='hover cell-border stripe',
#    options = list(scrollX = TRUE, pageLength=5)
#  )

```

### 2. Protein Collection

```{r}
Protein_collection <- read_excel(paste0(here::here(),"/Data/LabelFree_Practice_Dataset.xlsx"), sheet = "Protein_Collection")
#Protein_collection <- read_excel("3A_Practice_DataFiles.xlsx", sheet = "Protein_Collection")
```

```{r, message=FALSE, warning=FALSE}

# DT::datatable(
#   Protein_collection,
#   clas='hover cell-border stripe',
#   options = list(scrollX = TRUE, pageLength=5)
# )
```


# III. Clean Data 

***Enter/edit the MSGf_SpecProb value (for rat, set to <= 2.7113E-8)***
```{r}
#Filter for pre-set FDR (DTRA Rat data MSGF_SpecProb <= 2.7113E-8) ###This is calculated based on an analysis of the global proteomics of the test organism
Mage_fdr_df = Mage %>% filter(MSGF_SpecProb <= 2.7113E-8)
```


###### Remove unnecessary columns from Mage_fdr_df
```{r, message=FALSE, warning=FALSE}
  #3. Remove unnecessary columns from Mage_fdr_df -> Create new Mage_df with only 'Job', 'QValue', 'MSGF_SpecProb', 'Peptide', 'Protein', 'Scan' columns
Mage_fdr_filtered = Mage_fdr_df[, c('Job', 'MSGF_SpecProb', 'Peptide', 'Protein', 'QValue', 'PepQValue', 'TotalIonIntensity', 'PeakArea')]
#unique(Mage_fdr_filtered$Job)

```


### Clean Peptide Syntax
```{r, message=FALSE, warning=FALSE}
  #Remove "*" from peptides and replace with "" (gsub function -> Removes 3+ occurances)
Mage_fdr_filtered$Peptide <- gsub("*","",as.character(Mage_fdr_filtered$Peptide), fixed = TRUE)

  #Check for and count remaining "*" in peptide 
Mage_fdr_filtered$Astrisk_count <- str_count(Mage_fdr_filtered$Peptide,'\\*')
#Verify all * have been removed by checking Astrisk_count column. All should have 0 value
```



# IV. Sum Redundant Peptides

**Combine Redundant peptides and sum their peak area values. Apply a counter to determine the amount of redundancy per peptide**

#Re-ordered Access Protocol 

```{r}
  #Create unique ID's for each row -> Needed to spread data  
Mage_fdr_filtered$ID <- seq.int(nrow(Mage_fdr_filtered))
  #Spread Job Column into individual Columns with PeakArea values 
Spread_df <- spread(Mage_fdr_filtered, Job, PeakArea, fill=0)

# SUM REDUNTANT REPORTER ION INTENSITIES ####
# Remove peptide redundancy and sum Reporter Ion values

# This line will combine duplicate Peptides and sum all ions
    # detach("package:plyr", unload = TRUE) ###This line is needed if dplyr error n()) occurs
```

```{r}
#********************************************************************
      #Paste the range of sample columns into the next function ("First_sample_job_number":"Last_sample_job_number", sum)
colnames(Spread_df)

# This line will combine duplicate Peptides and sum all ions
Pep_redundency_df <- Spread_df %>%
  group_by(Peptide) %>%
  summarise(across("1953988":"1954014", sum))
```

```{r}
#Convert Peak Area Columns with 0 to NA values 
Pep_redundency_df[Pep_redundency_df == 0] <- NA

# Create df with columns that were removed in Pep_redundency
  # Counts the number of duplicate $Peptides
Missing_Columns_df <- Spread_df %>%
  group_by(Peptide) %>% 
  mutate(Pep_count = n()) 
  # Remove all Peak Area columns 
Missing_Columns_df <- Missing_Columns_df %>%
  select('Protein', 'Peptide' , 'Pep_count', 'MSGF_SpecProb')
  # Remove all redundancy of $Peptide and other columns missing from df1 
Missing_Columns_df <- distinct(Missing_Columns_df, Peptide, .keep_all = TRUE)

# Merge these two dataframes together and (B)re-organize 
Analysis_df = merge(Missing_Columns_df, Pep_redundency_df, by = 'Peptide', all.x = FALSE) 

```

```{r}
# Re-organize the df 
#********************************************************************
      #Look at Col names in Console     
colnames(Analysis_df)
      #Look at Metadata Job IDs and dataset Organize sample_job_numbers. ABP samples first, Comp Samples Next, NP Samples Last for the following function.
Analysis_df = Analysis_df %>%
  select('Protein', 'Peptide','Pep_count', 'MSGF_SpecProb', '1954012', '1954013', '1954014', '1954000', '1954001', '1954002', '1953988','1953989', '1953990')

      #Check Order of sample_job_numbers
colnames(Analysis_df)

```

**Analysis dataframe - This datatable should have a column for Job, QValue, Protein, Peptide, Pep_count, and all samples (reference sample, ABP, Comp, NP)**
```{r}
# DT::datatable(
#   Analysis_df,
#   clas='hover cell-border stripe',
#   options = list(scrollX = TRUE, pageLength=5)
# )
Analysis_df
```

```{r}
# create a pmart object
# do the duplicate process beforehand
edata <- Analysis_df %>%
  dplyr::select(-c(Protein,Pep_count,MSGF_SpecProb))
colnames(edata)[-1] <- paste0("Ion_",colnames(edata)[-1])
emeta <- Analysis_df %>%
  dplyr::select(c(Protein,Peptide,Pep_count,MSGF_SpecProb))
fdata <- read_excel(paste0(here::here(),"/Data/LabelFree_Practice_Dataset.xlsx"), sheet = "Metadata")
fdata$Job <- paste0("Ion_",fdata$Job)

unlabel_obj <- pmartR::as.pepData(e_data = edata, edata_cname = "Peptide",
                                        f_data = fdata, fdata_cname = "Job",
                                        e_meta = emeta, emeta_cname = "Protein")
saveRDS(unlabel_obj,paste0(here::here(),"/Data/unlabel_obj.RDS"))
```


# V. Box Plots and Central Tendency Normalization
### 1. Pre-Normalization Box Plot 
```{r, message=FALSE, warning=FALSE}
# LOG TRANSFORMATION, CENTRAL TENDENCY NORMALIZATION, ANTILOG ####
# Create Box blot before Central Tendency Normalization
  # Group samples for box plot (reference, ABP, Competitor, NP)
#*******************************************************************
    #Adjust Job ID set  select(First_job_column_position:last_job_column_position)
bp_initial = Analysis_df %>%
  select( 5:13)
#colnames(bp_initial) <-c('ABP1', 'ABP2', 'ABP3','Comp1', 'Comp2', 'Comp3','NP1', 'NP2','NP3')

bp_initial = log2(bp_initial)
  # melt "test" into Variables and values for boxplot
bp_initial_plot <- melt(bp_initial)

  # Initial Box Plot 
ggplot(bp_initial_plot, aes(
  x = variable, 
  y = value, 
  fill = variable), na.rm=TRUE) +
  geom_boxplot() 


```


### 2. Central Tendency Normalization

**Central Tendency Normalization is applied to each sample group separately**

```{r, message=FALSE, warning=FALSE}

# Perform log2 Transformation (reduces varience)
#*******************************************************************
    #input entire set of sample columns [x:y]
log2_data <- Analysis_df
log2_data[,5:13] <- log(log2_data[5:13], 2)

# Separate sample groups by creating individual dataframes
  # df with only ABP samples 
#*******************************************************************
    #Input column number set of ABP samples [ABPx:ABPy]
Cen_ten_ABP <- log2_data[5:7]
  # Remove infinite errors 
is.na(Cen_ten_ABP) <- do.call(cbind, lapply(Cen_ten_ABP, is.infinite)) 
  # df with only Comp samples
#*******************************************************************
    #Input column number set of Comp samples [Compx:Compy]
Cen_ten_Comp <- log2_data[8:10]
  # Remove infinite errors 
is.na(Cen_ten_Comp) <- do.call(cbind, lapply(Cen_ten_Comp, is.infinite))
#*******************************************************************
    #Input column number set of NP samples [NPx:NPy]
  # df with only NP samples
Cen_ten_NP <- log2_data[11:13]
  # Remove infinite errors 
is.na(Cen_ten_NP) <- do.call(cbind, lapply(Cen_ten_NP, is.infinite))

#Apply Central Tendency Normalization for each sample group (Probe, competitor and NP)
      #Function workflow -> (1) Compute mean of each column/replicate. (2) subtract the column mean from the values while centering at the max mean)
Mean_cen_ABP <- MeanCenter.Sub(Cen_ten_ABP, Mean=TRUE, centerZero = FALSE)
Mean_cen_Comp <- MeanCenter.Sub(Cen_ten_Comp, Mean=TRUE, centerZero = FALSE)
Mean_cen_NP <- MeanCenter.Sub(Cen_ten_NP, Mean=TRUE, centerZero = FALSE)

# Combine results into one df 
Normalized_df <- cbind(log2_data[1:4], Mean_cen_ABP, Mean_cen_Comp, Mean_cen_NP)
```

### 3. Normalized Box Plot
```{r, message=FALSE, warning=FALSE}

# Create Box Plot of the Normalized data
#*******************************************************************
    #input entire set of sample columns (x:y)
bp_normal = Normalized_df %>%
  select(5:13) 

bp_normal_plot <- melt(bp_normal)

# Box Plot 
ggplot(bp_normal_plot, aes(
  x = variable, 
  y = value, 
  fill = variable), na.rm=TRUE) +
  geom_boxplot() 

```

### 4. Antilog of Peak Area Ion Values 
```{r,  message=FALSE, warning=FALSE}
# Antilog of reporter ions 
  # Copy Normalized_df dataframe
Antilog_df <- Normalized_df

# Take antilog of all reporter ion columns 
#*******************************************************************
    #input entire set of sample columns x:y
Antilog_df[,5:13] <-  2^(Antilog_df[5:13])

```


# VI. Protein Roll Up 
**Combine Redundant Proteins and sum their reporter ion values. Apply a counter (Unique_Pep_count) to determine the amount of Unique peptides per Protein. Sum the redundant peptides to get total peptides per protein (Pep_count)**
```{r, message=FALSE, warning=FALSE}
# PROTEIN ROLLUP ####
# Protein Rollup - Combine duplicate Proteins and sum all ions
  # Duplicate Antilog_df 
Pro_redundency <- Antilog_df
Pro_redundency <- subset(Pro_redundency, select = -Peptide)

#Turn NA values to 0
Pro_redundency[is.na(Pro_redundency)] <- 0 

```

```{r}
  # Combine duplicate Proteins and sum all ions
#*******************************************************************
colnames(Pro_redundency)
    #Adjust Job ID set      select(First_job_column_position:last_job_column_position)
Pro_redundency <- Pro_redundency %>%
  group_by(Protein) %>%
  summarise(across("1954012":"1953990",sum, na.rm = TRUE))
  # Change 0 values back to NA
#Pro_redundency <- na_if(Pro_redundency, 0)
Pro_redundency[Pro_redundency ==0] <- NA

# Create df with columns that were removed in Antilog_df
  # Counts the number of duplicate $Proteins into Unique_pep_count
Missing_Columns_pro <- Antilog_df %>%
  group_by(Protein) %>% 
  mutate(Unique_Pep_count = n()) 

  # Remove all Peak Area columns 
Missing_Columns_pro <- Missing_Columns_pro %>%
  select('Protein', 'Unique_Pep_count', 'Pep_count')

  # Create new df with column with total protein count
Total_pep_count <- Missing_Columns_pro %>%
  group_by(Protein) %>%
  summarise(across(Pep_count, sum))

  # Important - this will remove all $Protein redundancy 
Missing_Columns_pro <- distinct(Missing_Columns_pro, Protein, .keep_all = TRUE)
  # Create C
Missing_Columns_pro <- Missing_Columns_pro[1:2]

#3. Merge the two dataframes together and (B)re-organize 
  # Merge Missing, Col, with Total_pep_count 
Roll_up_df = merge(Missing_Columns_pro, Total_pep_count,  by = 'Protein', all.x = FALSE) 
  # Merge with Pro_redundency 
Rolled_up_df = merge(Roll_up_df, Pro_redundency, by = 'Protein', all.x = FALSE) 
  # Remove 'Peptide' and 'QValue' Columns 
colnames(Rolled_up_df)
#Rolled_up_df <- subset(Rolled_up_df, select = -QValue)

```

```{r}
# DT::datatable(
#   Rolled_up_df,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=10, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
Rolled_up_df
```



# VII. Remove Reverse Hits and Contaminants
**Create two columns to ID rows as TRUE/FALSE if Protein column contains "XXX" or "Contaminant." Remove all rows that contain a TRUE conditional in column "XXX" or "Contaminant"**
```{r}
# Add observation counts 
  # Copy Roll_up_df2 dataframe  
xxx_rm <- Rolled_up_df

  # Create column "XXX" and "Contaminants and ID if Protein column contains these elements 
xxx_rm$XXX = grepl("XXX", xxx_rm$Protein, ignore.case = TRUE)
xxx_rm$Contaminant = grepl("Contaminant", xxx_rm$Protein, ignore.case = TRUE)

  # Create dataframe Stat_df containing rows where XXX == FALSE and Contaminant == FALSE elements
Stat_df = filter(xxx_rm, xxx_rm$XXX == FALSE & xxx_rm$Contaminant == FALSE)
```

**Scroll to the right to check if all XXX and Reverse Hits have been removed. All values should be 'FALSE'**
```{r}
  # Display Stat_df Dataframe
# DT::datatable(
#   Stat_df,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=10, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
Stat_df
```

# VIII. Add Protein Collection List 
```{r}

Stat_Protein_df <- merge(x = Stat_df, y = Protein_collection, by.x = ("Protein"), by.y = ("Protein_Name"), all.x = TRUE)
```

```{r}

# DT::datatable(
#   Stat_Protein_df,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
Stat_Protein_df
```


# IX. Statistical Analysis for each Comparision (ABP vs. NP)
### 1. Create Dataframe with Only Test Group Reporter Ions (ABP, NP)
  **Check to make sure ABP and NP columns are in this dataframe**

```{r}
#Set ABP and NP columns [X:Y] (ABP goes in 2nd set, NP goes in 3rd set)
ABP_NP_df <- cbind(Stat_Protein_df[1:3], Stat_Protein_df[4:6], Stat_Protein_df[10:12], Stat_Protein_df[13:21])
```

```{r}
# DT::datatable(
#   ABP_NP_df,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
ABP_NP_df
```


### 2. Count Valid Values (ABP vs. NP)
```{r}
# Count for ABP samples per protein
ABP_NP_df$Count_ABP <- rowSums(!is.na(ABP_NP_df[,4:6]))

# Count for NP samples per protein 
ABP_NP_df$Count_NP <- rowSums(!is.na(ABP_NP_df[,7:9]))

```

### 3. Apply Presence Absence Filter (ABP vs. NP)

**Save Resulting Dataset (ABP vs. NP Pres_Abs Results) **
```{r}
ABP_NP_Pres_Abs = filter(ABP_NP_df, ABP_NP_df$Count_ABP >= 2 & ABP_NP_df$Count_NP <= 1)
```

```{r}

# DT::datatable(
#   ABP_NP_Pres_Abs,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# ) 
ABP_NP_Pres_Abs
```

### 4. Apply t-Test Valid Values Filter (ABP vs. NP)
```{r}
#Need at least 2 measurements in each group to perform Welch's t-Test
ABP_NP_ttest = filter(ABP_NP_df, ABP_NP_df$Count_ABP >= 2 & ABP_NP_df$Count_NP >= 2)

```

### 5. Run t-Test Function (ABP vs. NP)

```{r}
# Log2 Transform Reporter Ions 
ABP_NP_log2 <- cbind(ABP_NP_ttest[1:3], log2(ABP_NP_ttest[4:9]), ABP_NP_ttest[10:20]) 

# t-Test function ABP vs. NP
ABP_NP_log2_Final <- cbind(ABP_NP_log2, row_t_welch(ABP_NP_log2[4:6], ABP_NP_log2[7:9], alternative = "greater"))

```

### 6. Run log2 Fold-Change Function (ABP vs. NP)
```{r}
# Re-organize dataframe to add t-test Results 
ABP_NP_Results <- ABP_NP_log2_Final

# Calculate and append Fold Change
ABP_NP_Results$Log2FC <- (rowMeans(ABP_NP_log2_Final[4:6], na.rm = TRUE) - rowMeans(ABP_NP_log2_Final[7:9], na.rm = TRUE))
```

**Re-Orangize Dataframe**
```{r}
# Note *Consider appending base and log2 df by Protein and not cbind*
ABP_NP_results_reordered = ABP_NP_Results %>%
  select(1, 'Description', 2:3,'pvalue', 'Log2FC', 4:38) 

```

### ABP vs. NP t_test and log2 FC Results
**Save Resulting Dataset (ABP vs. NP t-Test Results)**
```{r}
# DT::datatable(
#   ABP_NP_results_reordered,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
ABP_NP_results_reordered
```


# IX. Statistical Analysis for each Comparision (ABP vs. Comp)
### 1. Create Dataframe with Only Test Group Reporter Ions (ABP, Comp)
  **Check to make sure ABP and Comp columns are in this dataframe**

```{r}
#Set ABP and Comp columns [X:Y] (ABP goes in 2nd set, Comp goes in 3rd set)
ABP_Comp_df <- cbind(Stat_Protein_df[1:3], Stat_Protein_df[4:6], Stat_Protein_df[7:9], Stat_Protein_df[13:21])

```

```{r}
# DT::datatable(
#   ABP_Comp_df,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
ABP_Comp_df
```


### 2. Count Valid Values (ABP vs. Comp)
```{r}
# Count for ABP samples per protein
ABP_Comp_df$Count_ABP <- rowSums(!is.na(ABP_Comp_df[,4:6]))

# Count for Comp samples per protein 
ABP_Comp_df$Count_Comp <- rowSums(!is.na(ABP_Comp_df[,7:9]))

```

### 3. Apply Presence Absence Filter (ABP vs. Comp)

**Save Resulting Dataset (ABP vs. Comp Pres_Abs Results) **
```{r}
ABP_Comp_Pres_Abs = filter(ABP_Comp_df, ABP_Comp_df$Count_ABP >= 2 & ABP_Comp_df$Count_Comp <= 1)

```

```{r}
# DT::datatable(
#   ABP_Comp_Pres_Abs,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# ) 
ABP_Comp_Pres_Abs
```

### 4. Apply t-Test Valid Values Filter (ABP vs. Comp)
```{r}
#Need at least 2 measurements in each group to perform Welch's t-Test
ABP_Comp_ttest = filter(ABP_Comp_df, ABP_Comp_df$Count_ABP >= 2 & ABP_Comp_df$Count_Comp >= 2)

```

### 5. Run t-Test Function (ABP vs. Comp)

```{r}
# Log2 Transform Reporter Ions 
ABP_Comp_log2 <- cbind(ABP_Comp_ttest[1:3], log2(ABP_Comp_ttest[4:9]), ABP_Comp_ttest[10:20]) 

# t-Test function ABP vs. Comp
ABP_Comp_log2_Final <- cbind(ABP_Comp_log2, row_t_welch(ABP_Comp_log2[4:6], ABP_Comp_log2[7:9], alternative = "greater"))

```

### 6. Run log2 Fold-Change Function (ABP vs. Comp)
```{r}
# Re-organize dataframe to add t-test Results 
ABP_Comp_Results <- ABP_Comp_log2_Final

# Calculate and append Fold Change
ABP_Comp_Results$Log2FC <- (rowMeans(ABP_Comp_log2_Final[4:6], na.rm = TRUE) - rowMeans(ABP_Comp_log2_Final[7:9], na.rm = TRUE))
```

**Re-Orangize Dataframe**
```{r}
# Note *Consider appending base and log2 df by Protein and not cbind*
ABP_Comp_results_reordered = ABP_Comp_Results %>%
  select(1, 'Description', 2:3,'pvalue', 'Log2FC', 4:38) 

```

### ABP vs. Comp t_test and log2 FC Results
**Save Resulting Dataset (ABP vs. Comp t-Test Results)**
```{r}
# DT::datatable(
#   ABP_Comp_results_reordered,
#   clas='hover cell-border stripe',
#   extensions = 'Buttons',
#   options = list(scrollX = TRUE, 
#                  pageLength=5, 
#                  dom='Bfrtip',
#                  buttons = c('copy', 'csv', 'excel', 'pdf', 'print'))
# )
ABP_Comp_results_reordered
```


```{r}
# create pepData and isobaric pepdata version
# generating a standard report template - what do they want as outputs (normalized data, stat results, plots)
```



```
###Session Info: 
```{r}
sessionInfo()
```